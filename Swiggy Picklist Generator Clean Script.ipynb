{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Swiggy Warehouse Picklist Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean Code without Examples and Code Runs\n",
        "\n",
        "This file contains a clean version of the code, designed for better readability and focus on the core logic. It does not include intermediate examples or code runs that might be present during development or exploratory analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz8mPLV8XPGz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBIzqvJrXXjJ"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['dt','length_in_cm', 'width_in_cm',\n",
        "       'height_in_cm','order_tag','location_code'], axis=1)\n",
        "print(\"Columns after removing 'dt' column:\")\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdfdf08f"
      },
      "outputs": [],
      "source": [
        "df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce', dayfirst=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLsOdv6iaAYX"
      },
      "outputs": [],
      "source": [
        "def orders_of_the_day(date):\n",
        "    return df[df['order_date']==date]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1apFemXnt8ue"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "from datetime import time\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1quH4-oegUa"
      },
      "outputs": [],
      "source": [
        "class PickList:\n",
        "    \"\"\"\n",
        "    Warehouse Pick-List Management System.\n",
        "    Handles order grouping, zone prioritization, bin-packing for picklists,\n",
        "    and time/weight constraint enforcement.\n",
        "    \"\"\"\n",
        "    POD_PRIORITIES = ['P1','P2','P3','P4','P5','P6','P9']\n",
        "\n",
        "    def __init__(self, dataframe, date):\n",
        "        \"\"\"\n",
        "        Initializes the PickList object for a specific operational date.\n",
        "        Filters main dataframe for the day's orders and splits them into a dictionary by priority.\n",
        "        \"\"\"\n",
        "        self.date = date\n",
        "        self.dataframe = orders_of_the_day(date)\n",
        "        self.pod_dict = {\n",
        "            pod: self.dataframe[self.dataframe['pod_priority'] == pod]\n",
        "            for pod in self.POD_PRIORITIES\n",
        "        }\n",
        "\n",
        "    def build_zone_dict(self, pod_priority):\n",
        "        \"\"\"\n",
        "        Groups the pod-specific data into warehouse zones.\n",
        "        Sorts SKUs within each zone by quantity to facilitate optimized picking.\n",
        "        \"\"\"\n",
        "        if pod_priority not in self.pod_dict:\n",
        "            raise ValueError(f\"Invalid pod priority: {pod_priority}\")\n",
        "\n",
        "        pod_df = self.pod_dict[pod_priority]\n",
        "        zone_dict = {\n",
        "            zone: pod_df[pod_df['zone'] == zone]\n",
        "            .sort_values(by=['sku', 'order_qty'], ascending=False)\n",
        "            for zone in pod_df['zone'].unique()\n",
        "        }\n",
        "        return zone_dict\n",
        "\n",
        "    def display_data(self, pod_priority, n=5):\n",
        "        \"\"\"Displays the top N rows of a specific priority level for inspection.\"\"\"\n",
        "        print(f\"DataFrame for pod priority: {pod_priority}\")\n",
        "        display(self.pod_dict[pod_priority].head(n))\n",
        "\n",
        "    def zone_counts(self, pod_priority):\n",
        "        \"\"\"Calculates the frequency of order lines (rows) appearing in each zone.\"\"\"\n",
        "        if pod_priority not in self.pod_dict:\n",
        "            raise ValueError(f\"Invalid pod priority: {pod_priority}\")\n",
        "\n",
        "        return (\n",
        "            self.pod_dict[pod_priority]\n",
        "            .groupby('zone')\n",
        "            .size()\n",
        "            .rename('count')\n",
        "            .sort_values(ascending=False)\n",
        "        )\n",
        "\n",
        "    def quantity_counts(self, pod_priority):\n",
        "        \"\"\"Calculates the total number of physical units required per zone.\"\"\"\n",
        "        if pod_priority not in self.pod_dict:\n",
        "            raise ValueError(f\"Invalid pod priority: {pod_priority}\")\n",
        "\n",
        "        return (\n",
        "            self.pod_dict[pod_priority]\n",
        "            .groupby('zone')['order_qty']\n",
        "            .sum()\n",
        "            .rename('total_order_qty')\n",
        "            .sort_values(ascending=False)\n",
        "        )\n",
        "\n",
        "    def build_zone_priority_queue(self, pod_priority):\n",
        "        \"\"\"\n",
        "        Creates a max-heap priority queue using negative quantity as the key.\n",
        "        Ensures that zones with the heaviest workload are processed first.\n",
        "        \"\"\"\n",
        "        global ZONE_PRIORITY_QUEUE\n",
        "        ZONE_PRIORITY_QUEUE = []\n",
        "\n",
        "        if pod_priority not in self.pod_dict:\n",
        "            raise ValueError(f\"Invalid pod priority: {pod_priority}\")\n",
        "\n",
        "        qty_series = self.quantity_counts(pod_priority)\n",
        "\n",
        "        for zone, total_qty in qty_series.items():\n",
        "            heapq.heappush(\n",
        "                ZONE_PRIORITY_QUEUE,\n",
        "                (-total_qty, zone, pod_priority)\n",
        "            )\n",
        "\n",
        "    def print_zone_priority_queue(self):\n",
        "        \"\"\"Prints the priority order of zones based on total unit volume.\"\"\"\n",
        "        global ZONE_PRIORITY_QUEUE\n",
        "\n",
        "        if not ZONE_PRIORITY_QUEUE:\n",
        "            print(\"Zone priority queue is empty.\")\n",
        "            return\n",
        "\n",
        "        print(\"Zone Priority Queue (Highest → Lowest total_order_qty):\")\n",
        "        temp_queue = ZONE_PRIORITY_QUEUE.copy()\n",
        "        heapq.heapify(temp_queue)\n",
        "\n",
        "        while temp_queue:\n",
        "            total_qty, zone, pod = heapq.heappop(temp_queue)\n",
        "            print(f\"Pod: {pod}, Zone: {zone}, Total Order Qty: {-total_qty}\")\n",
        "\n",
        "    def Generate_picklist(self, pod_priority):\n",
        "        \"\"\"\n",
        "        Main algorithm for generating optimized picklists.\n",
        "        Uses a First-Fit Decreasing bin-packing approach to group SKUs\n",
        "        while respecting Time, Unit, and Weight constraints.\n",
        "        \"\"\"\n",
        "        global ZONE_PRIORITY_QUEUE\n",
        "        global ZONE_PICKLIST_QUEUE\n",
        "        global ZONE_PICKLIST_DICT\n",
        "\n",
        "        if not ZONE_PRIORITY_QUEUE:\n",
        "            print(\"Zone priority queue is empty.\")\n",
        "            return {}\n",
        "\n",
        "        ZONE_PICKLIST_QUEUE = []\n",
        "        ZONE_PICKLIST_DICT = {}\n",
        "\n",
        "        zone_dict = self.build_zone_dict(pod_priority)\n",
        "        temp_queue = ZONE_PRIORITY_QUEUE.copy()\n",
        "        heapq.heapify(temp_queue)\n",
        "\n",
        "        # Setting time constraints based on Priority Level (POD)\n",
        "        if pod_priority in ['P1','P2']:\n",
        "            MAX_TIME_SEC = 140 * 60  # 140 mins for High Priority\n",
        "        elif pod_priority in ['P3','P4','P5','P6']:\n",
        "            MAX_TIME_SEC = 50 * 60   # 50 mins for Standard\n",
        "        else:\n",
        "            MAX_TIME_SEC = 110 * 60  # Default 110 mins\n",
        "\n",
        "        MAX_UNITS = 2000\n",
        "\n",
        "        while temp_queue:\n",
        "            neg_qty, zone, pod = heapq.heappop(temp_queue)\n",
        "            zone_df = zone_dict.get(zone)\n",
        "            if zone_df is None or zone_df.empty:\n",
        "                continue\n",
        "\n",
        "            # Fragile zones have lower weight capacity\n",
        "            weight_limit = 50000 if zone == \"FRAGILE_FD\" else 200000\n",
        "\n",
        "            # Aggregate SKU data for efficient bin-packing\n",
        "            sku_summary = (\n",
        "                zone_df.groupby('sku')\n",
        "                .agg(total_units=('order_qty', 'sum'), total_weight=('weight_in_grams', 'sum'))\n",
        "                .reset_index()\n",
        "                .sort_values(by='total_units', ascending=False)\n",
        "            )\n",
        "\n",
        "            picklist_bins = []\n",
        "\n",
        "            for _, sku_row in sku_summary.iterrows():\n",
        "                sku_id, sku_units, sku_weight = sku_row['sku'], sku_row['total_units'], sku_row['total_weight']\n",
        "                sku_df = zone_df[zone_df['sku'] == sku_id]\n",
        "\n",
        "                placed = False\n",
        "                # Attempt to fit SKU into existing picklist bins\n",
        "                for bin_data in picklist_bins:\n",
        "                    temp_df = pd.concat([bin_data['df'], sku_df])\n",
        "                    estimated_time = self.calculate_picklist_time(temp_df)\n",
        "                    total_units = temp_df['order_qty'].sum()\n",
        "\n",
        "                    if (estimated_time <= MAX_TIME_SEC and\n",
        "                        bin_data['weight'] + sku_weight <= weight_limit and\n",
        "                        total_units <= MAX_UNITS):\n",
        "                        bin_data['df'] = temp_df\n",
        "                        bin_data['weight'] += sku_weight\n",
        "                        placed = True\n",
        "                        break\n",
        "\n",
        "                # Create a new bin if the SKU doesn't fit in existing ones\n",
        "                if not placed:\n",
        "                    picklist_bins.append({'df': sku_df.copy(), 'weight': sku_weight})\n",
        "\n",
        "            # Sort items inside picklist by location for Serpentine Path optimization\n",
        "            zone_picklists = [\n",
        "                bin_data['df'].sort_values(by=['floor', 'aisle', 'rack'], ascending=[True, True, True])\n",
        "                for bin_data in picklist_bins\n",
        "            ]\n",
        "\n",
        "            ZONE_PICKLIST_DICT[zone] = zone_picklists\n",
        "            heapq.heappush(ZONE_PICKLIST_QUEUE, (-len(zone_picklists), zone))\n",
        "\n",
        "    def calculate_picklist_time(self, picklist_df):\n",
        "        \"\"\"\n",
        "        Mathematical model to estimate the time a picker takes to complete a list.\n",
        "        Factors: Travel, unique SKU location stops, scanning/picking units, and unloading.\n",
        "        \"\"\"\n",
        "        if picklist_df is None or picklist_df.empty:\n",
        "            return 0\n",
        "\n",
        "        start_to_zone, zone_to_staging = 120, 120  # Fixed overhead\n",
        "        intra_zone_time = picklist_df['sku'].nunique() * 30  # Stop time per SKU\n",
        "        pickup_time = picklist_df['order_qty'].sum() * 5     # Handling time per Unit\n",
        "        unloading_time = picklist_df['order_id'].nunique() * 30 # Post-pick sorting\n",
        "\n",
        "        return start_to_zone + intra_zone_time + pickup_time + unloading_time + zone_to_staging\n",
        "\n",
        "    def display_generate_picklist_output(self):\n",
        "        \"\"\"Prints a summary of all generated picklists for the current session.\"\"\"\n",
        "        global ZONE_PICKLIST_QUEUE, ZONE_PICKLIST_DICT\n",
        "\n",
        "        if not ZONE_PICKLIST_QUEUE or not ZONE_PICKLIST_DICT:\n",
        "            print(\"Picklists have not been generated yet.\")\n",
        "            return\n",
        "\n",
        "        print(\"===== GENERATED PICKLIST OUTPUT =====\\n\")\n",
        "        temp_queue = ZONE_PICKLIST_QUEUE.copy()\n",
        "        heapq.heapify(temp_queue)\n",
        "\n",
        "        while temp_queue:\n",
        "            neg_batches, zone = heapq.heappop(temp_queue)\n",
        "            batch_count = -neg_batches\n",
        "            print(f\"Zone: {zone} | Total Picklists: {batch_count}\")\n",
        "\n",
        "            for i, batch_df in enumerate(ZONE_PICKLIST_DICT.get(zone, []), start=1):\n",
        "                total_units = batch_df['order_qty'].sum()\n",
        "                total_weight = batch_df['weight_in_grams'].sum() / 1000\n",
        "                time_sec = self.calculate_picklist_time(batch_df)\n",
        "\n",
        "                print(f\"Picklist {i}: {time_sec / 60:.2f} minutes\")\n",
        "                print(f\"  └─ {total_units} units | {total_weight:.2f} kg\")\n",
        "                display(batch_df)\n",
        "\n",
        "    def export_picklists_to_csv(self, output_dir, start_rank):\n",
        "        \"\"\"\n",
        "        Saves picklists to CSV files using a flat folder structure.\n",
        "        Ensures filenames are unique by using a global counter (start_rank).\n",
        "        \"\"\"\n",
        "        global ZONE_PICKLIST_DICT\n",
        "\n",
        "        if not ZONE_PICKLIST_DICT:\n",
        "            return start_rank\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        clean_date = str(self.date).split(' ')[0] # Remove 00:00:00 timestamp\n",
        "\n",
        "        # Gather all zone batches for unified sorting by time\n",
        "        all_batches = []\n",
        "        for zone, picklists in ZONE_PICKLIST_DICT.items():\n",
        "            for batch_df in picklists:\n",
        "                time_sec = self.calculate_picklist_time(batch_df)\n",
        "                all_batches.append({\"time_sec\": time_sec, \"df\": batch_df.copy()})\n",
        "\n",
        "        # Sort all lists globally (longest tasks first)\n",
        "        all_batches.sort(key=lambda x: x[\"time_sec\"], reverse=True)\n",
        "\n",
        "        current_rank = start_rank\n",
        "        for record in all_batches:\n",
        "            df = record[\"df\"].reset_index(drop=True)\n",
        "            picklist_id = f\"PL_{current_rank:03d}\"\n",
        "\n",
        "            df['order_date'] = clean_date\n",
        "            df['picklist_no'] = picklist_id\n",
        "            df['bin_rank'] = df.index + 1\n",
        "\n",
        "            # Select required columns for export\n",
        "            export_df = df[['order_date', 'picklist_no', 'sku', 'store_id', 'bin', 'bin_rank']]\n",
        "\n",
        "            # Filename: YYYY-MM-DD_RANK.csv\n",
        "            filename = f\"{clean_date}_{current_rank:03d}.csv\"\n",
        "            export_df.to_csv(os.path.join(output_dir, filename), index=False)\n",
        "            current_rank += 1\n",
        "\n",
        "        return current_rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkvuBehE7Oiv"
      },
      "outputs": [],
      "source": [
        "POD_PRIORITIES = ['P1','P2','P3','P4','P5','P6','P9']\n",
        "os.makedirs(\"Warehouse_Operations\", exist_ok=True)\n",
        "\n",
        "def run_consolidated_warehouse_workflow(df, base_dir=\"Warehouse_Operations\"):\n",
        "    \"\"\"\n",
        "    Orchestrates the end-to-end picklist generation process across multiple dates.\n",
        "\n",
        "    This function handles:\n",
        "    1. Date-wise folder creation.\n",
        "    2. Chronological processing of unique dates.\n",
        "    3. Maintaining a global file rank (001, 002...) to prevent overwriting across priorities.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Identify and sort all unique dates in the dataset for sequential processing\n",
        "    unique_dates = sorted(df['order_date'].unique())\n",
        "\n",
        "    for current_date in unique_dates:\n",
        "        # 2. Date Cleaning: Remove timestamps (e.g., '00:00:00') for folder naming\n",
        "        clean_date_str = str(current_date).split(' ')[0]\n",
        "        date_folder = os.path.join(base_dir, clean_date_str)\n",
        "        os.makedirs(date_folder, exist_ok=True)\n",
        "\n",
        "        # 3. Initialize the PickList engine for the specific date\n",
        "        pl_engine = PickList(df, current_date)\n",
        "\n",
        "        # 4. Global Counter: This prevents filename collisions between P1, P2, etc.\n",
        "        # Reset to 1 at the start of every new date folder.\n",
        "        global_day_rank = 1\n",
        "\n",
        "        # 5. Iterate through each Priority (POD) level defined in the class\n",
        "        for priority in pl_engine.POD_PRIORITIES:\n",
        "            # Skip priorities that have no orders on this specific date\n",
        "            if priority not in pl_engine.pod_dict or pl_engine.pod_dict[priority].empty:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # 6. Rank Zones: Determine which areas have the highest volume first\n",
        "                pl_engine.build_zone_priority_queue(priority)\n",
        "\n",
        "                # 7. Pack Bins: Apply constraints (Weight/Time/Units) to group SKUs\n",
        "                pl_engine.Generate_picklist(priority)\n",
        "\n",
        "                # 8. Export & Update: Save CSVs to the date folder.\n",
        "                # The function returns the NEXT available rank number to maintain continuity.\n",
        "                global_day_rank = pl_engine.export_picklists_to_csv(date_folder, global_day_rank)\n",
        "\n",
        "            except Exception as e:\n",
        "                # Catch-all for unexpected errors during a priority run to keep the loop moving\n",
        "                print(f\"Error processing {priority} on {clean_date_str}: {e}\")\n",
        "                pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXsQLUT7IrSB"
      },
      "outputs": [],
      "source": [
        "pick_list_obj=PickList(df,'2025-11-08')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1bgXbN0RWHo"
      },
      "outputs": [],
      "source": [
        "pick_list_obj.build_zone_dict('P1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9kpsuE7RYwm"
      },
      "outputs": [],
      "source": [
        "pick_list_obj.display_data('P1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeXd8mTvRroy"
      },
      "outputs": [],
      "source": [
        "pick_list_obj.build_zone_priority_queue('P1')\n",
        "pick_list_obj.print_zone_priority_queue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKpU7G8gR08x"
      },
      "outputs": [],
      "source": [
        "pick_list_obj.Generate_picklist('P1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfwZmWaMR647"
      },
      "outputs": [],
      "source": [
        "pick_list_obj.display_generate_picklist_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx6DDJfjSNqv"
      },
      "outputs": [],
      "source": [
        "run_consolidated_warehouse_workflow(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
